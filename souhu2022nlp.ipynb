{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-13T19:03:53.826010Z","iopub.execute_input":"2022-05-13T19:03:53.827078Z","iopub.status.idle":"2022-05-13T19:03:53.872318Z","shell.execute_reply.started":"2022-05-13T19:03:53.826916Z","shell.execute_reply":"2022-05-13T19:03:53.871227Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/souhu2022/generated_train_data_piece.txt\n/kaggle/input/souhu2022/generated_test_data_piece.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ntrain = pd.read_json('../input/souhu2022/generated_train_data_piece.txt', lines = True)\ntest = pd.read_json('../input/souhu2022/generated_test_data_piece.txt', lines = True)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:03:53.874190Z","iopub.execute_input":"2022-05-13T19:03:53.874701Z","iopub.status.idle":"2022-05-13T19:03:55.385545Z","shell.execute_reply.started":"2022-05-13T19:03:53.874654Z","shell.execute_reply":"2022-05-13T19:03:55.384545Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id                                            content entity  label\n0   1  3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制纺织品服装的刚性消费...     美国      0\n1   1  3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制纺织品服装的刚性消费...     中国      0\n2   2  显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...     德约     -1\n3   2  显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...  梅德韦杰夫      1\n4   2  显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...     澳网      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>content</th>\n      <th>entity</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制纺织品服装的刚性消费...</td>\n      <td>美国</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制纺织品服装的刚性消费...</td>\n      <td>中国</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...</td>\n      <td>德约</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...</td>\n      <td>梅德韦杰夫</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...</td>\n      <td>澳网</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:03:55.387283Z","iopub.execute_input":"2022-05-13T19:03:55.387510Z","iopub.status.idle":"2022-05-13T19:03:55.398804Z","shell.execute_reply.started":"2022-05-13T19:03:55.387481Z","shell.execute_reply":"2022-05-13T19:03:55.397721Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        id                                            content     entity\n0  5000001  然而作为同龄的选手，王涵也不想把所有的压力都压在施廷懋一人的肩上，“当然我也可以给予她一些帮...        施廷懋\n1  5000001  然而作为同龄的选手，王涵也不想把所有的压力都压在施廷懋一人的肩上，“当然我也可以给予她一些帮...         王涵\n2  5000002  ◆诺贝尔奖是如何评选的据诺贝尔奖委员会官网介绍，诺贝尔奖由瑞典发明家、企业家阿尔弗雷德·诺贝...  阿尔弗雷德·诺贝尔\n3  5000002  ◆诺贝尔奖是如何评选的据诺贝尔奖委员会官网介绍，诺贝尔奖由瑞典发明家、企业家阿尔弗雷德·诺贝...    诺贝尔奖委员会\n4  5000003  上半场比赛中威少这边的进攻状态依旧不是太好，只不过对比威少以往的表现，这场比赛威少的进攻也算...         威少","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>content</th>\n      <th>entity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5000001</td>\n      <td>然而作为同龄的选手，王涵也不想把所有的压力都压在施廷懋一人的肩上，“当然我也可以给予她一些帮...</td>\n      <td>施廷懋</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5000001</td>\n      <td>然而作为同龄的选手，王涵也不想把所有的压力都压在施廷懋一人的肩上，“当然我也可以给予她一些帮...</td>\n      <td>王涵</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5000002</td>\n      <td>◆诺贝尔奖是如何评选的据诺贝尔奖委员会官网介绍，诺贝尔奖由瑞典发明家、企业家阿尔弗雷德·诺贝...</td>\n      <td>阿尔弗雷德·诺贝尔</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5000002</td>\n      <td>◆诺贝尔奖是如何评选的据诺贝尔奖委员会官网介绍，诺贝尔奖由瑞典发明家、企业家阿尔弗雷德·诺贝...</td>\n      <td>诺贝尔奖委员会</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5000003</td>\n      <td>上半场比赛中威少这边的进攻状态依旧不是太好，只不过对比威少以往的表现，这场比赛威少的进攻也算...</td>\n      <td>威少</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['text'] = '目标:' + train['entity'] + '[SEP]' + train['content']\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:03:55.400608Z","iopub.execute_input":"2022-05-13T19:03:55.400851Z","iopub.status.idle":"2022-05-13T19:03:55.435089Z","shell.execute_reply.started":"2022-05-13T19:03:55.400823Z","shell.execute_reply":"2022-05-13T19:03:55.434058Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id                                            content entity  label  \\\n0   1  3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制纺织品服装的刚性消费...     美国      0   \n1   1  3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制纺织品服装的刚性消费...     中国      0   \n2   2  显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...     德约     -1   \n3   2  显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...  梅德韦杰夫      1   \n4   2  显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...     澳网      0   \n\n                                                text  \n0  目标:美国[SEP]3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制...  \n1  目标:中国[SEP]3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制...  \n2  目标:德约[SEP]显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托...  \n3  目标:梅德韦杰夫[SEP]显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本...  \n4  目标:澳网[SEP]显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>content</th>\n      <th>entity</th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制纺织品服装的刚性消费...</td>\n      <td>美国</td>\n      <td>0</td>\n      <td>目标:美国[SEP]3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制纺织品服装的刚性消费...</td>\n      <td>中国</td>\n      <td>0</td>\n      <td>目标:中国[SEP]3.新疆棉是全球业界公认的高品质天然纤维原料，较好满足了全球范围内对棉制...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...</td>\n      <td>德约</td>\n      <td>-1</td>\n      <td>目标:德约[SEP]显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...</td>\n      <td>梅德韦杰夫</td>\n      <td>1</td>\n      <td>目标:梅德韦杰夫[SEP]显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托在梅德韦杰夫身上。去...</td>\n      <td>澳网</td>\n      <td>0</td>\n      <td>目标:澳网[SEP]显然，与其指望德约在罗兰-加洛斯击败纳达尔，不如把希望寄托在墨尔本，寄托...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport random\nimport warnings\nfrom collections import defaultdict\nimport sys\nsys.path.append('./nezha')\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, AutoModel, AutoConfig, AutoTokenizer\nfrom transformers import get_linear_schedule_with_warmup\nfrom tqdm import tqdm\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:03:55.437894Z","iopub.execute_input":"2022-05-13T19:03:55.438324Z","iopub.status.idle":"2022-05-13T19:04:04.779754Z","shell.execute_reply.started":"2022-05-13T19:03:55.438275Z","shell.execute_reply":"2022-05-13T19:04:04.777855Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Config:\n    apex = False\n    seed = 42\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    num_workers = 0\n    \n    model_type = 'roberta'\n    model_name = 'hfl/chinese-roberta-wwm-ext'\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    \n    text_col = 'text'\n    target_col = 'label'\n    target_size = 5\n    max_len = 400\n    batch_size = 8\n    n_fold = 2\n    trn_folds = [0, 1]\n    \n    epochs = 4\n    lr = 2e-5\n    eps = 1e-6\n    betas = (0.9, 0.999)\n    num_warmup_steps = 0.03\n    T_0 = 2\n    min_lr = 1e-6\n    \n    weight_decay = 0.01\n    gradient_accumulation_steps = 1\n    max_grad_norm = 1.0\n    \n    save_prefix = model_name.split('/')[-1]\n\nCFG = Config()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:04.781152Z","iopub.execute_input":"2022-05-13T19:04:04.781422Z","iopub.status.idle":"2022-05-13T19:04:20.316303Z","shell.execute_reply.started":"2022-05-13T19:04:04.781391Z","shell.execute_reply":"2022-05-13T19:04:20.315093Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/19.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"999916cac4dc417fbf41abcf27a37e84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/689 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a271e7dc22e4c43b45c69063a6f3527"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/107k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f83c64b8eb4d4355ac0cf311809b13ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/263k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb27a83939bb45faaa594536c05bb358"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55e935c14c4d4a9dabad333713b6a0e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31914a75076240468d561076dac33655"}},"metadata":{}}]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    \"\"\"\n    设置随机种子\n    \"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\nseed_torch(CFG.seed) # 固定运行环境","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.317692Z","iopub.execute_input":"2022-05-13T19:04:20.317966Z","iopub.status.idle":"2022-05-13T19:04:20.328811Z","shell.execute_reply.started":"2022-05-13T19:04:20.317927Z","shell.execute_reply":"2022-05-13T19:04:20.327807Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class SentimentDataset(Dataset):\n    def __init__(self, texts, targets, labels, tokenizer, max_len):\n        self.texts = texts\n        self.targets = targets\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, item):\n        '''\n        item is the index of data,迭代取第item条数据\n        '''\n        text = str(self.texts[item])\n        target = str(self.targets[item])\n        label = self.labels[item]\n        \n        encoding = self.tokenizer.encode_plus(text,\n                                             target,\n                                             truncation = 'only_first', #True/only_first，将每个文本序列截断到模型可以接受的最大长度\n                                            add_special_tokens = True,\n                                            max_length = self.max_len,\n                                              return_token_type_ids = True,\n                                              pad_to_max_length = True,\n                                              return_attention_mask = True,\n                                              return_tensors = 'pt', #返回张量\n                                             )\n        \n        return {'texts': text,\n               'input_ids': encoding['input_ids'].flatten(), #对应于文本序列中每个token的索引（在vocab中的索引）\n               'attention_mask': encoding['attention_mask'].flatten(), #对应于注意力机制的计算，各元素的值为0或1，如果当前token被mask或者是只是用来作为填充的元素，那么其不需要进行注意力机制的计算，其值为0；\n               'token_type_ids': encoding['token_type_ids'].flatten(),#对应于不同的文本序列，例如在NSP（BERT及某些语言模型中的“Next Sentence Prediction”）任务中需要输入两个文本序列。\n               'labels': torch.tensor(label, dtype = torch.long)\n               }","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.332711Z","iopub.execute_input":"2022-05-13T19:04:20.332998Z","iopub.status.idle":"2022-05-13T19:04:20.346120Z","shell.execute_reply.started":"2022-05-13T19:04:20.332966Z","shell.execute_reply":"2022-05-13T19:04:20.344990Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# def create_data_loader(df, tokenzier, max_len, batch_size, is_shuffle = False):\n#     ds = SentimentDataset(texts = df['text'].values,\n#                          targets = df['entity'].values,\n#                          labels = df['label'].values,\n#                          tokenizer = tokenizer,\n#                          max_len = max_len\n#                          )\n#     return DataLoader(ds,\n#                      batch_size = batch_size,\n#                      shuffle = is_shuffle,\n#                      pin_memory = True, #设置pin_memory=True，则意味着生成的Tensor数据最开始是属于内存中的锁页内存，这样将内存的Tensor转义到GPU的显存就会更快一些；配置好，设置为锁页内存；默认为False，即不锁页内存\n#                      )\n\ndef create_data_loader(df, tokenizer, max_len, batch_size, is_shuffle=False):\n    ds = SentimentDataset(\n        texts=df['text'].values,\n        targets=df['entity'].values,\n        labels=df['label'].values,\n        tokenizer=tokenizer,\n        max_len=max_len\n    )\n\n    return DataLoader(\n        ds,\n        batch_size=batch_size,\n        shuffle=is_shuffle,\n        pin_memory=True,\n        # num_workers=4  # windows多线程\n    )","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.347597Z","iopub.execute_input":"2022-05-13T19:04:20.347865Z","iopub.status.idle":"2022-05-13T19:04:20.367609Z","shell.execute_reply.started":"2022-05-13T19:04:20.347815Z","shell.execute_reply":"2022-05-13T19:04:20.366651Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class CLSModel(nn.Module):\n    def __init__(self, model_name, n_classes):\n        super(ClSModel, self).__init__()\n        config = AutoConfig.from_pretrained(model_name)\n        self.model = AutoModel.from_pretrained(model_name, config = config)\n        self.linear = nn.Linear(config.hidden_size, n_classes)\n    \n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.model(input_ids, attention_mask, token_type_ids)\n        last_hidden_state = outputs[0]\n        cls_embeddings = last_hidden_state[:, 0] # pooler out\n        logits = self.linear(cls_embeddings)\n        return logits\n ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.368904Z","iopub.execute_input":"2022-05-13T19:04:20.369239Z","iopub.status.idle":"2022-05-13T19:04:20.388344Z","shell.execute_reply.started":"2022-05-13T19:04:20.369207Z","shell.execute_reply":"2022-05-13T19:04:20.387628Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, epoch):\n    model = model.train()\n    losses = []\n    predictions = []\n    real_values = []\n    tqdm_bar = tqdm(data_loader, total = len(data_loader), desc = f'training epoch\"\\t {epoch}')\n    for batch in tqdm_bar:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        token_type_ids = batch['token_type_ids'].to(device)\n        targets = batch['labels'].to(device)\n        \n        outputs = model(input_ids = input_ids,\n                       attention_mask = attention_mask,\n                       token_type_ids = token_type_ids\n                       )\n        loss = loss_fn(outputs, targets)\n        _, preds = torch.max(outputs, dim = 1) #返回每一行中最大值的那个元素，且返回其索引(代表类别)\n        \n        losses.append(loss.item()) # !!!!!!!!!\n        loss.backward() #不是优化器，也可以反向传播嘛？\n        \n        tqdm_bar.set_postfix_str(f'running training loss:{loss.item():.4f}')\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm = 5.0) #梯度裁剪。在BP过程中会产生梯度消失（就是偏导无限接近0，导致长时记忆无法更新），可以设定阈值，当梯度小于阈值时，更新的梯度为阈值，（梯度裁剪解决的是梯度消失或爆炸的问题）\n        optimizer.step() #对模型参数进行更新\n        scheduler.step() #对lr进行调整，如果scheduler.step()是放在batch里面，指的是经过step_size次的迭代，学习率改变一次\n        optimizer.zero_grad()\n        \n        predictions.extend(preds) #.extend() 在列表末尾一次性追加另一个序列的多个值\n        real_values.extend(targets)\n    predictions = torch.stack(predictions).cpu() # torch.stack()增加新的维度进行堆叠\n    real_values = torch.stack(real_values).cpu()\n    return f1_score(predictions, real_values, average = 'macro'), np.mean(losses)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.391477Z","iopub.execute_input":"2022-05-13T19:04:20.391834Z","iopub.status.idle":"2022-05-13T19:04:20.410399Z","shell.execute_reply.started":"2022-05-13T19:04:20.391794Z","shell.execute_reply":"2022-05-13T19:04:20.409277Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, epoch):\n    model = model.eval() #验证预测模式\n    losses = []\n    predictions = []\n    real_values = []\n    with torch.no_grad(): #上下文管理器，被该语句 wrap 起来的部分将不会track 梯度，执行计算时，该计算不会被反向传播记录\n        for batch in tqdm(data_loader, total = len(data_loader), desc = f'evaluating:\\t {epoch}'):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            targets = batch['labels'].to(device)\n            \n            outputs = model(input_ids = input_ids,\n                           attention_mask = attention_mask,\n                           token_type_ids = token_type_ids)\n            _, preds = torch.max(outputs, dim = 1)\n            loss = loss_fn(outputs, targets)\n            losses.append(loss.item())\n            predictions.extend(preds)\n            real_values.extend(targets)\n    predictions = torch.stack(predictions).cpu()\n    real_values = torch.stack(real_values).cpu()\n    return f1_score(predictions, real_values, average = 'macro'), np.mean(losses)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.412374Z","iopub.execute_input":"2022-05-13T19:04:20.413391Z","iopub.status.idle":"2022-05-13T19:04:20.434374Z","shell.execute_reply.started":"2022-05-13T19:04:20.413327Z","shell.execute_reply":"2022-05-13T19:04:20.433322Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha = 1, gamma = 2, reduce = True):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduce = reduce\n    \n    def forward(self, inputs, targets):\n        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n        pt = torch.exp(-BCE_loss) #变为指数\n        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n        if self.reduce:\n            return torch.mean(F_loss)\n        else:\n            return F_loss\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.436480Z","iopub.execute_input":"2022-05-13T19:04:20.437254Z","iopub.status.idle":"2022-05-13T19:04:20.454357Z","shell.execute_reply.started":"2022-05-13T19:04:20.437215Z","shell.execute_reply":"2022-05-13T19:04:20.453292Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train_cv():\n    best_scores = []\n    skf = StratifiedKFold(n_splits = CFG.n_fold, shuffle = True, random_state = CFG.seed)\n    for n, (train_index, val_index) in enumerate(skf.split(train, train[CFG.target_col])):\n        if n in CFG.trn_folds:\n            print(f'Fold {n + 1} / {CFG.n_fold}')\n            print('***' * 10)\n            \n            df_train = train.loc[train_index]\n            df_val = train.loc[val_index]\n            train_data_loader = create_data_loader(df_train, CFG.tokenizer, CFG.max_len, CFG.batch_size, True)\n            val_data_loader = create_data_loader(df_val, CFG.tokenizer, CFG.max_len, CFG.batch_size, False)\n            model = LastHiddenModel(CFG.model_name, CFG.target_size)\n            model = model.to(CFG.device)\n            \n            no_decay = ['bias', 'LayerNorm.weight']\n            \n            param_optimizer = list(model.named_parameters())\n            optimizer_grouped_parameters = [\n                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n                 'weight_decay_rate': CFG.weight_decay},\n                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n                 'weight_decay_rate': 0.0}\n            ]\n            \n            optimizer = AdamW(optimizer_grouped_parameters, lr = CFG.lr, weight_decay = CFG.weight_decay)\n            total_steps = len(train_data_loader) * CFG.epochs\n            scheduler = get_linear_schedule_with_warmup(optimizer,\n                                                       num_warmup_steps = CFG.num_warmup_steps,\n                                                       num_training_steps = total_steps)\n            loss_fn = FocalLoss().to(CFG.device)\n            \n            history = defaultdict(list) #记录10轮loss和acc\n            best_accuracy = 0\n            \n            for epoch in range(CFG.epochs):\n                train_acc, train_loss = train_epoch(model,\n                                                   train_data_loader,\n                                                   loss_fn,\n                                                   optimizer,\n                                                   CFG.device,\n                                                   scheduler,\n                                                   epoch,)\n                print(f'\\n Train loss {train_loss} accuracy {train_acc}')\n                \n                val_acc, val_loss = eval_model(model,\n                                              val_data_loader,\n                                              loss_fn, \n                                              CFG.device,\n                                              epoch)\n                print(f'\\n Val loss {val_loss} accuracy{val_acc}')\n                \n                history['train_acc'].append(train_acc)\n                history['train_loss'].append(train_loss)\n                history['val_acc'].append(val_acc)\n                history['val_loss'].append(val_loss)\n                \n                if val_acc > best_accuracy:\n                    torch.save(model.state_dict(), f'models/{CFG.save_prefix}_best_model_fold{n}.bin')\n                    best_accuracy = val_acc\n            best_scores.append(best_accuracy)\n    print(best_scores)\n    print(np.mean(best_scores))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.455855Z","iopub.execute_input":"2022-05-13T19:04:20.456135Z","iopub.status.idle":"2022-05-13T19:04:20.477737Z","shell.execute_reply.started":"2022-05-13T19:04:20.456102Z","shell.execute_reply":"2022-05-13T19:04:20.476712Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_predictions(model, data_loader):\n    model = model.eval()\n    predictions_probs = []\n    with torch.no_grad():\n        for d in tqdm(data_loader,):\n            input_ids = d[\"input_ids\"].to(CFG.device)\n            attention_mask = d[\"attention_mask\"].to(CFG.device)\n            token_type_ids = d[\"token_type_ids\"].to(CFG.device)\n            \n            outputs = model(input_ids = input_ids,\n                           attention_mask = attention_mask,\n                           token_type_ids = token_type_ids)\n            probs = outputs.softmax(1)\n            prediction_probs.extend(probs)\n    predicitons_probs = torch.stack(predicitons_probs).cpu()\n    return prediction_probs\n","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.479010Z","iopub.execute_input":"2022-05-13T19:04:20.479247Z","iopub.status.idle":"2022-05-13T19:04:20.498341Z","shell.execute_reply.started":"2022-05-13T19:04:20.479219Z","shell.execute_reply":"2022-05-13T19:04:20.497404Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class LastHiddenModel(nn.Module):\n    def __init__(self, model_name, n_classes):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(model_name)\n\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(config.hidden_size, n_classes)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.model(input_ids, attention_mask, token_type_ids)# last_hidden_state和pooler out\n        last_hidden_state = outputs[0] # 所有字符最后一层hidden state # 32 400 768 ，但是PAD PAD\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        logits = self.linear(mean_embeddings)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.500296Z","iopub.execute_input":"2022-05-13T19:04:20.500536Z","iopub.status.idle":"2022-05-13T19:04:20.513284Z","shell.execute_reply.started":"2022-05-13T19:04:20.500508Z","shell.execute_reply":"2022-05-13T19:04:20.512083Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_cv()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T19:04:20.514557Z","iopub.execute_input":"2022-05-13T19:04:20.514842Z","iopub.status.idle":"2022-05-13T19:05:10.661938Z","shell.execute_reply.started":"2022-05-13T19:04:20.514811Z","shell.execute_reply":"2022-05-13T19:05:10.660439Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Fold 1 / 2\n******************************\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/393M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02293c609f9640bcad74e5b158bb4670"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\ntraining epoch\"\t 0:   0%|          | 0/1438 [00:10<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1526395380.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_33/3048492246.py\u001b[0m in \u001b[0;36mtrain_cv\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                                                    \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                                    \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                                    epoch,)\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n Train loss {train_loss} accuracy {train_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/123985350.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m                        \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                        )\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#返回每一行中最大值的那个元素，且返回其索引(代表类别)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/317489188.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mBCE_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mBCE_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#变为指数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mF_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBCE_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1164\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: Target -1 is out of bounds."],"ename":"IndexError","evalue":"Target -1 is out of bounds.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}